作业-1 Transformer 中的并行策略与通信分析

## 1 并行策略与张量 shape

### 1.1

#### 1.1.1
对于 `Linear1`，权重矩阵 $$W_1$$ 的 shape 为 `[d, 4d]`，即 `[1024, 4096]`。当使用 `P=4` 的列并行（Column Parallel）时，我们将权重矩阵 $$W_1$$ 沿着列（第二个维度）进行切分。因此，每个 rank 上的权重矩阵 $$W_1^{(i)}$$ 的 shape 是 `[d, 4d/P]`，即 ****。

#### 1.1.2
在 `Linear1` 的前向传播中，输入张量 $$X$$ (shape: `[B, S, d]`) 与切分后的权重矩阵 $$W_1^{(i)}$$ (shape: `[d, 4d/P]`) 进行矩阵乘法。根据矩阵乘法的规则，输入张量 $$X$$ 不需要被切分，每个 rank 都会接收到完整的输入张量 $$X$$。因此，每个 rank 输入的张量 $$X$$ 的 shape 仍然是 `[B, S, d]`，即 ****。

#### 1.1.3
在每个 rank `i` 上，本地的矩阵乘法是 $$Y_i = X \cdot W_1^{(i)}$$。输入 $$X$$ 的 shape 是 `[B, S, d]`，$$W_1^{(i)}$$ 的 shape 是 `[d, 4d/P]`，因此本地输出 $$Y_i$$ 的 shape 是 `[B, S, 4d/P]`，即 ****。

为了得到完整的输出 $$Y$$ (shape: `[B, S, 4d]`)，需要将所有 rank 上的本地输出 $$Y_i$$ 沿着第二个维度（列维度）进行拼接（Concatenate）。然而，在 Megatron-LM 的典型实现中，为了优化通信，并不会立即进行 `all-gather` 操作来获取完整的 $$Y$$。 因为紧接着的 `Linear2` 使用的是行并行，它可以直接消费分片的输入。 因此，这里的本地输出 $$Y_i$$ 经过 GeLU 激活函数后，会直接作为下一层的输入，从而避免了通信。

### 1.2

#### 1.2.1
对于 `Linear2`，权重矩阵 $$W_2$$ 的 shape 为 `[4d, d]`，即 `[4096, 1024]`。当使用 `P=4` 的行并行（Row Parallel）时，我们将权重矩阵 $$W_2$$ 沿着行（第一个维度）进行切分。因此，每个 rank 上的权重矩阵 $$W_2^{(i)}$$ 的 shape 是 `[4d/P, d]`，即 ****。

#### 1.2.2
`Linear2` 的输入是 `Linear1` 经过 GeLU 激活函数后的输出。由于 `Linear1` 采用了列并行，其输出在各个 rank 上是分片的，每个 rank 上的输出 shape 为 `[B, S, 4d/P]`。GeLU 激活函数是逐元素操作，不改变张量的 shape。因此，每个 rank 接受的输入张量的 shape 是 `[B, S, 4d/P]`，即 ****。

#### 1.2.3
在每个 rank `i` 上，本地的矩阵乘法是 $$Z_i = Y_i \cdot W_2^{(i)}$$。输入 $$Y_i$$ 的 shape 是 `[B, S, 4d/P]`，$$W_2^{(i)}$$ 的 shape 是 `[4d/P, d]`，因此本地输出 $$Z_i$$ 的 shape 是 `[B, S, d]`，即 ****。

为了得到最终的完整输出 $$Z$$ (shape: `[B, S, d]`)，需要将所有 rank 上的本地输出 $$Z_i$$ 进行求和。这个操作通过一次 `all-reduce` 通信完成。 每个 rank 都会得到求和后的完整输出 $$Z$$。

## 2 通信分析

### 2.1

#### 2.1.1
在前向传播中，`Linear1` (Column Parallel) 的计算是 $$Y_i = \text{GeLU}(X \cdot W_1^{(i)})$$。输入 $$X$$ 是完整的，权重 $$W_1$$ 是按列切分的。每个 rank 可以独立地计算其部分的输出 $$Y_i$$。如 1.1.3 所述，由于 `Linear2` 采用行并行，可以直接使用分片的 $$Y_i$$ 作为输入。因此，**在前向传播中，`Linear1` 之后不需要通信**。

#### 2.1.2
在反向传播中，我们需要计算损失函数 $$L$$ 对输入 $$X$$ 的梯度 $$\partial L / \partial X$$。根据链式法则，$$\partial L / \partial X = (\partial L / \partial Y) \cdot W_1^T$$。在这里，$$\partial L / \partial Y$$ 是从 `Linear2` 反向传播回来的梯度，它的 shape 与 $$Y$$ 一致，是 `[B, S, 4d]`，并且在各个 rank 上是分片的（因为 `Linear2` 的前向是 `all-reduce`，所以其反向的梯度是分片的）。具体来说，每个 rank `i` 持有 $$\partial L / \partial Y_i$$。而 $$W_1$$ 在各个 rank 上是按列切分的 $$W_1^{(i)}$$。

为了计算完整的 $$\partial L / \partial X$$，每个 rank 需要完整的 $$W_1$$。然而，更高效的做法是，每个 rank 计算一个部分的梯度 $$\partial L / \partial X_i = (\partial L / \partial Y_i) \cdot (W_1^{(i)})^T$$，然后对所有 rank 的结果进行 `all-reduce` 求和，得到最终的 $$\partial L / \partial X$$。因此，**计算 $$\partial L / \partial X$$ 需要通信**。

**通信操作是 `all-reduce`**。
**通信量分析**：
每个 rank 计算出的部分梯度 $$\partial L / \partial X_i$$ 的 shape 是 `[B, S, d]`。
通信量 = `B * S * d * sizeof(element)`
通信量 = `8 * 128 * 1024 * 4 bytes` (假设为 32 位浮点数) = **4 MB**。

### 2.2

#### 2.2.1
在前向传播中，`Linear2` (Row Parallel) 的计算是 $$Z_i = Y_i \cdot W_2^{(i)}$$。输入 $$Y_i$$ 是分片的，权重 $$W_2$$ 是按行切分的。每个 rank 计算出一个部分的输出 $$Z_i$$。为了得到最终的完整输出 $$Z$$，需要将所有 rank 上的 $$Z_i$$ 进行求和。因此，**前向传播需要通信**。

**通信操作是 `all-reduce`**。
**通信量分析**：
每个 rank 上的本地输出 $$Z_i$$ 的 shape 是 `[B, S, d]`。
通信量 = `B * S * d * sizeof(element)`
通信量 = `8 * 128 * 1024 * 4 bytes` = **4 MB**。

#### 2.2.2
在反向传播中，我们需要计算损失函数 $$L$$ 对 `Linear2` 输入 $$Y$$ 的梯度 $$\partial L / \partial Y$$。根据链式法则，$$\partial L / \partial Y = (\partial L / \partial Z) \cdot W_2^T$$。`Linear2` 的前向传播有一个 `all-reduce`，所以它的输出 $$Z$$ 在所有 rank 上是相同的。因此，从上层传来的梯度 $$\partial L / \partial Z$$ 在所有 rank 上也是完整的。

每个 rank `i` 持有完整的 $$\partial L / \partial Z$$ 和部分的权重 $$W_2^{(i)}$$。它可以独立计算出其对应的部分梯度 $$\partial L / \partial Y_i = (\partial L / \partial Z) \cdot (W_2^{(i)})^T$$。这个计算不需要与其他 rank 通信，因为每个 rank 只需要计算自己负责的那部分梯度。因此，**计算 $$\partial L / \partial Y$$ 不需要通信**。

## 3 如果两层都使用 Row Parallel，会产生哪些额外通信？两层都使用 Column Parallel 会带来什么问题？

**如果两层都使用 Row Parallel:**
1.  **`Linear1` (Row Parallel)**:
    *   **前向传播**: 为了进行矩阵乘法，输入 $$X$$ 需要沿着最后一个维度 `d` 被切分。这将引入一次 `split` 或者 `scatter` 操作。`Linear1` 的输出是部分结果，需要一次 `all-reduce` 来得到完整的输出 $$Y$$，以便送入 `Linear2`。
    *   **`Linear2` (Row Parallel)**:
    *   **前向传播**: 输入 $$Y$$ 同样需要被切分，又是一次 `split`。然后 `Linear2` 的输出需要再次 `all-reduce`。
*   **额外通信**: 相比于标准的列并行+行并行组合，这种策略会在 `Linear1` 的前向传播后引入一次 `all-reduce`，并且可能需要在 `Linear1` 和 `Linear2` 的输入处都进行数据切分，这破坏了流水线式的计算流程，增加了通信开销和等待时间。

**如果两层都使用 Column Parallel:**
1.  **`Linear1` (Column Parallel)**:
    *   **前向传播**: 和标准策略一样，输出是分片的 $$Y_i$$，无需通信。
2.  **`Linear2` (Column Parallel)**:
    *   **前向传播**: `Linear2` 采用列并行，其权重 $$W_2$$ 按列（`d` 维度）切分。但它的输入 $$Y$$ 来自 `Linear1`，是按 `4d` 维度切分的。这两个切分维度不匹配，无法直接进行矩阵乘法。
*   **问题**: 为了让 `Linear2` 能够进行计算，必须先将 `Linear1` 的分片输出 $$Y_i$$ 通过 `all-gather` 操作聚合成完整的 $$Y$$。这个 `all-gather` 操作会产生巨大的通信开销。
    *   **通信量**: `all-gather` 会将每个 rank 的 `[B, S, 4d/P]` 数据发送给所有其他 `P-1` 个 rank。总通信量约为 `P * B * S * (4d/P) * sizeof(element) = 4 * B * S * 4d * sizeof(element) = 4 * 8 * 128 * 4096 * 4 bytes = 64 MB`。这是一个非常大的通信量，会严重影响性能。

标准的**列并行 + 行并行**组合之所以高效，是因为它巧妙地避免了在前向传播的 FFN 模块中间进行通信。`Linear1` 的分片输出可以直接被 `Linear2` 作为输入，将通信（`all-reduce`）推迟到了 `Linear2` 计算之后，从而实现了计算和通信的优化。