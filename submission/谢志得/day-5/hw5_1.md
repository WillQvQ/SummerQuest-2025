# 答题卡

## 1 并行策略与张量 shape

### 1.1

#### 1.1.1
$(d,4d/P)=(1024,1024)$

#### 1.1.2
$(B,S,d)=(8,128,1024)$

#### 1.1.3
$(B,S,4d/P)=(8,128,1024)$，按照第三维拼接在一起

### 1.2


#### 1.2.1
$(4d/P,d)=(1024,1024)$

#### 1.2.2
$(B,S,4d/P)=(8,128,1024)$

#### 1.2.3
$(B,S,d)=(8,128,1024)$，相加

## 2 通信分析

### 2.1

#### 2.1.1
如果一开始 $X$ 就在每个 rank 上，就不需要通信。

如果不在，需要一次 broadcast，通信量为 $(P-1)BSd$。

#### 2.1.2
需要，$Y_i=XW_1^{(i)},\frac{\part L}{\part X}=\sum_i W_1^{(i)}\frac{\part L}{\part Y_i}$，所以要一次 reduce。

### 2.2

#### 2.2.1
需要，allreduce，$2(P-1)Bsd$

#### 2.2.2
$Z=\sum Z_i,Z_i=Y_iW_2^{(i)},\frac{\part L}{\part Y_i}=W_2^{(i)}\frac{\part L}{\part Z}$。

如果 $\frac{\part L}{\part Z}$ 已经分给了每个 rank，则不需要通信，否则需要一次 broadcast。

# 3 如果两层都使用 Row Parallel，会产生哪些额外通信？两层都使用 Column Parallel 会带来什么问题？
两层都用 Row Parallel：前向传播时，第一层结束后需要 reduce 和 scatter，反向时也要对应多两个操作。

两层都用 Column Parallel：前向时多一次 allgather，反向时对应的也要多操作。因为一直都要存完整的 X，所以还会用更多的显存。