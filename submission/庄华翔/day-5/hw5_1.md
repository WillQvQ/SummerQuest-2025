# 答题卡

## 1 并行策略与张量 shape

### 1.1

#### 1.1.1
每个 rank 上的权重矩阵 $W_1^{(i)}$ shape 是：$[1024, 1024]$

Column Parallel 将权重矩阵按列维度切分，原始权重 $W_1 \in \mathbb{R}^{d \times 4d} = \mathbb{R}^{1024 \times 4096}$，切分到 4 个 rank 上，每个 rank 的权重维度为 $[1024, 4096/4] = [1024, 1024]$。

#### 1.1.2
每个 rank 输入的张量 $X$ 的 shape 是：$[8, 128, 1024]$

Column Parallel 中，输入张量 $X$ 在所有 rank 上完全复制，因此每个 rank 接收到的输入张量形状与原始输入相同，为 $[B, S, d] = [8, 128, 1024]$。

#### 1.1.3
每个 rank 本地输出 $Y_i$ 的 shape 是：$[8, 128, 1024]$

最终通过沿着隐藏维度拼接得到完整的 $Y$：$Y = \text{concat}([Y_0, Y_1, Y_2, Y_3], \text{dim}=-1)$，最终 $Y$ 的 shape 为 $[8, 128, 4096]$。

### 1.2

#### 1.2.1
每个 rank 上的权重矩阵 $W_2^{(i)}$ shape 是：$[1024, 1024]$

Row Parallel 将权重矩阵按行维度切分，原始权重 $W_2 \in \mathbb{R}^{4d \times d} = \mathbb{R}^{4096 \times 1024}$，切分到 4 个 rank 上，每个 rank 的权重维度为 $[4096/4, 1024] = [1024, 1024]$。

#### 1.2.2
每个 rank 接受输入的张量的 shape 是：$[8, 128, 1024]$

Row Parallel 中，输入张量需要按隐藏维度切分分发到各个 rank，每个 rank 接收到输入张量的 1/4，形状为 $[8, 128, 4096/4] = [8, 128, 1024]$。

#### 1.2.3
每个 rank 本地输出 $Z_i$ 的 shape 是：$[8, 128, 1024]$

最终通过 All-Reduce 操作对所有 rank 的输出求和得到完整的 $Z$：$Z = \sum_{i=0}^{3} Z_i$，最终 $Z$ 的 shape 为 $[8, 128, 1024]$。

## 2 通信分析

### 2.1

#### 2.1.1
前向传播不需要通信。

Column Parallel 中，每个 rank 使用完整的输入 $X$ 和自己的权重分片进行计算，输出结果直接拼接，无需额外通信。

#### 2.1.2
反向传播时，计算 $\partial L / \partial X$ 需要通信。

因为前向传播时输出是拼接得到的，反向传播时梯度需要通过 All-Reduce 操作将各个 rank 上对输入 $X$ 的梯度进行求和，通信量为 $8 \times 128 \times 1024 \times 4 \text{ bytes} = 4,194,304 \text{ bytes}$（假设使用 float32）。

### 2.2

#### 2.2.1
前向传播需要通信。通信操作是 All-Reduce。通信量是 $8 \times 128 \times 1024 \times 4 = 4,194,304 \text{ bytes}$。

Row Parallel 中，各个 rank 的输出需要通过 All-Reduce 求和得到最终结果，通信量为输出张量的大小。

#### 2.2.2
反向传播时，计算 $\partial L / \partial X$ 不需要通信。

因为前向传播时已经进行了 All-Reduce，反向传播时梯度可以直接分发到各个 rank，无需额外的 All-Reduce 操作。

# 3 如果两层都使用 Row Parallel，会产生哪些额外通信？两层都使用 Column Parallel 会带来什么问题？

**两层都使用 Row Parallel 的额外通信：**
- Linear1 的输出需要进行 All-Reduce 通信
- Linear1 输出到 Linear2 输入之间需要重新切分分发，产生额外的 All-to-All 通信
- 总通信量显著增加，包括两次 All-Reduce 和一次 All-to-All 操作

**两层都使用 Column Parallel 的问题：**
- Linear1 的输出是按隐藏维度拼接的完整张量 $[8, 128, 4096]$
- Linear2 需要的是完整输入，但 Column Parallel 要求输入在所有 rank 上复制
- 需要进行广播操作将 Linear1 的输出复制到所有 rank，通信开销很大
- 或者需要重新切分 Linear1 的输出，这会破坏 Column Parallel 的设计初衷

**最优方案：** Linear1 使用 Column Parallel，Linear2 使用 Row Parallel，这样可以避免中间的额外通信，实现高效的流水线计算。