# 特殊词符(Special Token)添加与生成任务总结

本文档总结了 Day-3 的两个任务完成情况：

## 任务一：为 Qwen3-8B 添加特殊词符

在这个任务中，我们为 Qwen3-8B 模型的 Tokenizer 添加了两个特殊词符：`<|AGENT|>` 和 `<|EDIT|>`。主要完成了以下步骤：

1. 加载 Qwen3-8B 的 Tokenizer
2. 添加 `<|AGENT|>` 和 `<|EDIT|>` 两个特殊词符
3. 将修改后的 Tokenizer 保存到本地
4. 使用修改后的 Tokenizer 解码 `query_and_output.json` 中的内容
5. 将解码结果（包含特殊词符的 Token IDs）保存到 `hw3_1.json`

通过查看 `hw3_1.json`，可以看到特殊词符被成功添加，并获得了对应的 Token ID：
- `<|AGENT|>` 的 Token ID 为 151669
- `<|EDIT|>` 的 Token ID 为 151670

## 任务二：设计系统提示词引导模型生成特殊词符

在这个任务中，我们设计了system prompt，引导 Qwen3-8B 模型生成包含特殊词符的输出。主要步骤包括：

1. 设计系统提示词，明确指导模型使用特殊词符的场景和格式
2. 使用 vLLM 引擎加载 Qwen3-8B 模型
3. 处理 `query_only.json` 中的查询，生成包含特殊词符的回答
4. 将生成结果保存到 `hw3_2.json`

系统提示词的设计思路是：
- 明确区分 `<|AGENT|>` 和 `<|EDIT|>` 两种模式的使用场景
- 提供清晰的响应格式，包括 `<think>` 部分和特殊词符的使用
- 指导模型根据查询类型（明确错误或模糊问题）选择合适的特殊词符
- 关联特殊词符与相应的工具调用（`<|AGENT|>` 与 python 函数，`<|EDIT|>` 与 editor 函数）

下面是检查结果
🚀 开始检查文件...
📁 文件路径: hw3_2.json

============================================================
📋 hw3_checker.py 检查结果
============================================================
📊 总体统计:
   总项目数: 10
   ✅ 通过: 1
   ❌ 失败: 9
   📈 通过率: 10.0%

🔍 问题统计:
   缺少特殊词符: 9 项

📝 详细检查结果:
   项目 0: ❌ 缺少特殊词符 <|EDIT|> 或 <|AGENT|>
   项目 1: ❌ 缺少特殊词符 <|EDIT|> 或 <|AGENT|>
   项目 2: ❌ 缺少特殊词符 <|EDIT|> 或 <|AGENT|>
   项目 3: ❌ 缺少特殊词符 <|EDIT|> 或 <|AGENT|>
   项目 4: ✅ 通过所有检查
   项目 5: ❌ 缺少特殊词符 <|EDIT|> 或 <|AGENT|>
   项目 6: ❌ 缺少特殊词符 <|EDIT|> 或 <|AGENT|>
   项目 7: ❌ 缺少特殊词符 <|EDIT|> 或 <|AGENT|>
   项目 8: ❌ 缺少特殊词符 <|EDIT|> 或 <|AGENT|>
   项目 9: ❌ 缺少特殊词符 <|EDIT|> 或 <|AGENT|>
============================================================

从 `hw3_2.json` 的结果可以看出，模型在少部分情况下能够根据系统提示词的指导，在适当的场景下使用特殊词符，并进行相应的工具调用。
